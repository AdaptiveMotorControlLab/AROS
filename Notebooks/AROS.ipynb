{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdaptiveMotorControlLab/AROS/blob/main/Notebooks/AROS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adversarially Robust Out-of-Distribution Detection Using Lyapunov-Stabilized Embeddings"
      ],
      "metadata": {
        "id": "RFxEz28oe7dE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook is designed to replicate and analyze the results presented in Table 1 of the AROS paper, focusing on out-of-distribution detection performance under both attack scenarios and clean evaluation. The dataset configurations involve using CIFAR-10 and CIFAR-100 as in-distribution and out-of-distribution datasets. The notebook is structured to load a pre-trained model as the encoder, followed by generating fake OOD embeddings through sampling. The model is then trained using the designed loss function and evaluated across various OOD detection benchmarks to assess its performance under different conditions.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZL5Va1N940xJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8i7kYslKnOhJ"
      },
      "source": [
        "#Import utils"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/AdaptiveMotorControlLab/AROS.git"
      ],
      "metadata": {
        "id": "TdY-7pyGq4oN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/AROS\n",
        "%ls\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "owrQtpTxrbth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "WgsBOHhNrtYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfFpweyoWApG"
      },
      "outputs": [],
      "source": [
        "%cd AROS\n",
        "from evaluate import *\n",
        "from utils import *\n",
        "from data_loader import *\n",
        "from stability_loss_function import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0VhjMLBnZ1e"
      },
      "source": [
        "#Set hyperparameters & dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdrVKMH0nZ_r"
      },
      "outputs": [],
      "source": [
        "parser = argparse.ArgumentParser(description=\"Hyperparameters for the script\")\n",
        "\n",
        "# Define the hyperparameters controlled via CLI 'Ding2020MMA'\n",
        "\n",
        "parser.add_argument('--in_dataset', type=str, default='cifar10', choices=['cifar10', 'cifar100'], help='The in-distribution dataset to be used')\n",
        "parser.add_argument('--threat_model', type=str, default='Linf', help='Adversarial threat model for robust training')\n",
        "parser.add_argument('--noise_std', type=float, default=1, help='Standard deviation of noise for generating noisy fake embeddings')\n",
        "parser.add_argument('--attack_eps', type=float, default=8/255, help='Perturbation bound (epsilon) for PGD attack')\n",
        "parser.add_argument('--attack_steps', type=int, default=10, help='Number of steps for the PGD attack')\n",
        "parser.add_argument('--attack_alpha', type=float, default=2.5 * (8/255) / 10, help='Step size (alpha) for each PGD attack iteration')\n",
        "\n",
        "args = parser.parse_args('')\n",
        "\n",
        "# Set the default model name based on the selected dataset\n",
        "if args.in_dataset == 'cifar10':\n",
        "    default_model_name = 'Rebuffi2021Fixing_70_16_cutmix_extra'\n",
        "elif args.in_dataset == 'cifar100':\n",
        "    default_model_name = 'Wang2023Better_WRN-70-16'\n",
        "\n",
        "parser.add_argument('--model_name', type=str, default=default_model_name, choices=['Rebuffi2021Fixing_70_16_cutmix_extra', 'Wang2023Better_WRN-70-16'], help='The pre-trained model to be used for feature extraction')\n",
        "\n",
        "# Re-parse arguments to include model_name selection based on the dataset\n",
        "args = parser.parse_args('')\n",
        "num_classes = 10 if args.in_dataset == 'cifar10' else 100\n",
        "\n",
        "trainloader, testloader,test_set, ID_OOD_loader = get_loaders(in_dataset=args.in_dataset)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jZhzNCFnjBK"
      },
      "source": [
        "#Fake embedding generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnjl5M8xLq2i"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "robust_backbone = load_model(model_name=args.model_name, dataset=args.in_dataset, threat_model=args.threat_model).to(device)\n",
        "\n",
        "\n",
        "\n",
        "last_layer_name, last_layer = list(robust_backbone.named_children())[-1]\n",
        "setattr(robust_backbone, last_layer_name, nn.Identity())\n",
        "fake_loader=None\n",
        "\n",
        "\n",
        "num_fake_samples = len(trainloader.dataset) // num_classes\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "embeddings, labels = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, lbls in trainloader:\n",
        "        imgs = imgs.to(device, non_blocking=True)\n",
        "        embed = robust_backbone(imgs).cpu()  # move to CPU only once per batch\n",
        "        embeddings.append(embed)\n",
        "        labels.append(lbls)\n",
        "embeddings = torch.cat(embeddings).numpy()\n",
        "labels = torch.cat(labels).numpy()\n",
        "\n",
        "\n",
        "print(\"embedding computed...\")\n",
        "\n",
        "\n",
        "if args.fast==False:\n",
        "  gmm_dict = {}\n",
        "  for cls in np.unique(labels):\n",
        "      cls_embed = embeddings[labels == cls]\n",
        "      gmm = GaussianMixture(n_components=1, covariance_type='full').fit(cls_embed)\n",
        "      gmm_dict[cls] = gmm\n",
        "\n",
        "  print(\"fake crafing...\")\n",
        "\n",
        "  fake_data = []\n",
        "\n",
        "\n",
        "  for cls, gmm in gmm_dict.items():\n",
        "      samples, likelihoods = [], []\n",
        "      while len(samples) < num_samples_needed:\n",
        "          s = gmm.sample(100)[0]\n",
        "          likelihood = gmm.score_samples(s)\n",
        "          samples.append(s[likelihood < np.quantile(likelihood, 0.001)])\n",
        "          likelihoods.append(likelihood[likelihood < np.quantile(likelihood, 0.001)])\n",
        "          if sum(len(smp) for smp in samples) >= num_samples_needed:\n",
        "              break\n",
        "      samples = np.vstack(samples)[:num_samples_needed]\n",
        "      fake_data.append(samples)\n",
        "\n",
        "  fake_data = np.vstack(fake_data)\n",
        "  fake_data = torch.tensor(fake_data).float()\n",
        "  fake_data = F.normalize(fake_data, p=2, dim=1)\n",
        "\n",
        "  fake_labels = torch.full((fake_data.shape[0],), 10)\n",
        "  fake_loader = DataLoader(TensorDataset(fake_data, fake_labels), batch_size=128, shuffle=True)\n",
        "\n",
        "if args.fast==True:\n",
        "\n",
        "\n",
        "    noise_std = 0.1  # standard deviation of noise\n",
        "    noisy_embeddings = torch.tensor(embeddings) + noise_std * torch.randn_like(torch.tensor(embeddings))\n",
        "\n",
        "    # Normalize Noisy Embeddings\n",
        "    noisy_embeddings = F.normalize(noisy_embeddings, p=2, dim=1)[:len(trainloader.dataset)//num_classes]\n",
        "\n",
        "    # Convert to DataLoader if needed\n",
        "    fake_labels = torch.full((noisy_embeddings.shape[0],), num_classes)[:len(trainloader.dataset)//num_classes]\n",
        "    fake_loader = DataLoader(TensorDataset(noisy_embeddings, fake_labels), batch_size=128, shuffle=True)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7ibC97YnxYq"
      },
      "source": [
        "#Train and eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsAOiMNbnyil"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "final_model = stability_loss_function_(trainloader, testloader, robust_backbone, num_classes, fake_loader, last_layer, args)\n",
        "\n",
        "\n",
        "test_attack = PGD_AUC(final_model, eps=args.attack_eps, steps=args.attack_steps, alpha=args.attack_alpha, num_classes=num_classes)\n",
        "get_clean_AUC(final_model, ID_OOD_loader , device, num_classes)\n",
        "adv_auc = get_auc_adversarial(model=final_model,  test_loader=ID_OOD_loader, test_attack=test_attack, device=device, num_classes=num_classes)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W18YwKYln36n"
      },
      "source": [
        "#Extra Experiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9xaiEJyPBdb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "!pip install wget\n",
        "import wget\n",
        "from pathlib import Path\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import tarfile\n",
        "\n",
        "image_size=32\n",
        "load_out_names=[ \"places365\",\"LSUN\", \"iSUN\" ]\n",
        "\n",
        "\n",
        "\n",
        "if \"places365\" in load_out_names:\n",
        "    # Define the directory path and create it if it does not exist\n",
        "    base_dir = \"./datasets/data\"\n",
        "    os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "    # Download and save categories_places365.txt\n",
        "    dest = os.path.join(base_dir, \"categories_places365.txt\")\n",
        "    if not Path(dest).is_file():\n",
        "        wget.download(\"https://dl.dropboxusercontent.com/s/enr71zpolzi1xzm/categories_places365.txt\", out=dest)\n",
        "\n",
        "    # Download and save places365_val.txt\n",
        "    dest = os.path.join(base_dir, \"places365_val.txt\")\n",
        "    if not Path(dest).is_file():\n",
        "        wget.download(\"https://dl.dropboxusercontent.com/s/gaf1ygpdnkhzyjo/places365_val.txt\", out=dest)\n",
        "\n",
        "    # Download and save val_256.tar\n",
        "    dest = os.path.join(base_dir, \"val_256.tar\")\n",
        "    if not Path(dest).is_file():\n",
        "        wget.download(\"https://dl.dropboxusercontent.com/s/3pwqsyv33f6if3z/val_256.tar\", out=dest)\n",
        "\n",
        "    # Extract val_256.tar if val_256 directory does not exist\n",
        "    dest_final = os.path.join(base_dir, \"val_256\")\n",
        "    if not Path(dest_final).is_dir():\n",
        "        with tarfile.open(dest) as tar:\n",
        "            tar.extractall(path=base_dir)\n",
        "\n",
        "    # Load the Places365 dataset\n",
        "    places365 = torchvision.datasets.Places365(\n",
        "        root=base_dir,\n",
        "        split='val',\n",
        "        small=True,\n",
        "        download=False,\n",
        "        transform=transforms.Compose([\n",
        "            transforms.Resize(image_size),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if \"LSUN\" in load_out_names:\n",
        "        # Define the base directory and ensure it exists\n",
        "        base_dir = \"./datasets/data\"\n",
        "        os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "        # Define the destination path for LSUN dataset\n",
        "        dest = os.path.join(base_dir, \"LSUN_resize.tar.gz\")\n",
        "        if not Path(dest).is_file():\n",
        "            wget.download(\"https://bit.ly/3wA55Wb\", out=dest)\n",
        "            with tarfile.open(dest) as tar:\n",
        "                tar.extractall(path=os.path.join(base_dir, \"LSUN_resize\"))\n",
        "\n",
        "        # Define transformation based on image size\n",
        "        transform = transforms.ToTensor() if image_size == 32 else transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Resize(image_size)\n",
        "        ])\n",
        "\n",
        "        # Load the LSUN dataset\n",
        "        LSUN = torchvision.datasets.ImageFolder(root=os.path.join(base_dir, \"LSUN_resize\"), transform=transform)\n",
        "\n",
        "\n",
        "if \"iSUN\" in load_out_names:\n",
        "        # Define the destination path for iSUN dataset\n",
        "        dest = os.path.join(base_dir, \"iSUN.tar.gz\")\n",
        "        if not Path(dest).is_file():\n",
        "            wget.download(\"https://bit.ly/3yRMTJe\", out=dest)\n",
        "            with tarfile.open(dest) as tar:\n",
        "                tar.extractall(path=os.path.join(base_dir, \"iSUN\"))\n",
        "\n",
        "        # Define transformation based on image size\n",
        "        transform = transforms.ToTensor() if image_size == 32 else transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Resize(image_size)\n",
        "        ])\n",
        "\n",
        "        # Load the iSUN dataset\n",
        "        iSUN = torchvision.datasets.ImageFolder(root=os.path.join(base_dir, \"iSUN\"), transform=transform)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class LabelChangedDataset(Dataset):\n",
        "    def __init__(self, original_dataset, new_label):\n",
        "        self.original_dataset = original_dataset\n",
        "        self.new_label = new_label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.original_dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image, _ = self.original_dataset[idx]\n",
        "        return image, self.new_label\n",
        "\n",
        "\n",
        "\n",
        "# Download and load the SVHN test set\n",
        "svhn = torchvision.datasets.SVHN(root='./datasets/data', split='test', download=True, transform=transform)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "iSUN = LabelChangedDataset(iSUN, num_classes)\n",
        "\n",
        "LSUN = LabelChangedDataset(LSUN, num_classes)\n",
        "\n",
        "places365 = LabelChangedDataset(places365, num_classes)\n",
        "\n",
        "\n",
        "svhn = LabelChangedDataset(svhn, num_classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zlRGcd5tMjIS"
      },
      "outputs": [],
      "source": [
        "test_dataset_isun = ConcatDataset([test_set, iSUN])\n",
        "\n",
        "testloader_isun = DataLoader(test_dataset_isun, shuffle=False, batch_size=64)\n",
        "\n",
        "get_clean_AUC(final_model, testloader_isun , device, num_classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMNqeiEdMmCi"
      },
      "outputs": [],
      "source": [
        "test_dataset_LSUN = ConcatDataset([test_set, LSUN])\n",
        "\n",
        "testloader_LSUN = DataLoader(test_dataset_LSUN, shuffle=False, batch_size=64)\n",
        "\n",
        "get_clean_AUC(final_model, testloader_LSUN, device, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dF7qrwnHsDhA"
      },
      "outputs": [],
      "source": [
        "test_dataset_places365 = ConcatDataset([test_set, places365])\n",
        "\n",
        "testloader_places365 = DataLoader(test_dataset_places365, shuffle=False, batch_size=64)\n",
        "\n",
        "get_clean_AUC(final_model, testloader_places365 , device, num_classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JY4i7mv_sIas"
      },
      "outputs": [],
      "source": [
        "test_dataset_svhn = ConcatDataset([test_set, svhn])\n",
        "\n",
        "testloader_svhn = DataLoader(test_dataset_svhn, shuffle=False, batch_size=64)\n",
        "\n",
        "get_clean_AUC(final_model, testloader_svhn , device, num_classes)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
